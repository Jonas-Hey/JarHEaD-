= Data store scale-out =

The {{PRODUCT}} provides services to third party systems by means of APIs, and to end users through web-based UIs, built on top of Wiki-based and Web 2.0 technologies, and fluidOps widgets.
The APIs, UIs, and widgets themselves rely on access to the platform’s application and DB services, which includes processing DB queries, executing data and infrastructure providers, and running workflows/jobs.

fluidOps makes sure that the throughput of a node is very high, by utilizing industry’s leading technologies and in-memory computing techniques.
Most applications and usage patterns run well on a single node, and most customers will start and for a very long time be able to stay on a single node architecture. This has the advantage of low administrative overhead and simple operations.
For protecting production application nodes please refer to the fluidOps High Availability description.

However, when a single node can not be scaled up anymore (i.e. by moving to a larger system with more/faster CPUs and/or memory), scaling out horizontally by a) separating the system into tiers or b) adding more compute nodes to build a clustered architecture can be a valid option.

== Cluster DB data store ==

In a multi-tiered architecture, several {{PRODUCT}} instances can be configured to form a cluster which would serve as a backend triple store by the connecting clients. 
Each client will communicate with the cluster as with a single triple store, while the actual backend node will be chosen by the cluster in order to optimize the workload.

The cluster protocol for detection of nodes is based on [https://ignite.apache.org/ Apache Ignite], and master election is based on the fluidOps Quorum mechanisms for the cluster. 
The cluster nodes all communicate over the network with each other. Each nodes sends out periodical pings to the other nodes, and exchanges current load statistics (CPU, memory) which can be used for placement of new workloads. 

For cluster detection and cluster registration, an extra range of network ports is used. The default range is 49500..49529, which makes it possible to run multiple instances on a single node (please note that in this case the fluidOps platform network ports need to be reconfigured as they are not automatically chosen).

The actual communication of nodes with each other takes place using the existing secure fluidOps communication infrastructure.

On the dedicated configuration pages, you can specify an instance of {{PRODUCT}} to be a [[Setup:ClusterDBBackend | backend cluster node]] or to connect to a cluster as a [[Setup:ClusterDBClient | client]].

A demonstration of this feature can be found <a href="https://www.youtube.com/watch?v=JBTx5JvDm4s">here</a>.
